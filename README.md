\# 3D Gaussian Splatting in Autonomous Driving: A Survey of Applications and Directions



\[!\[arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](http://arxiv.org/abs/your-paper-id) \[!\[License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)



This repository is the official implementation and resource collection for the paper \*\*"3D Gaussian Splatting in Autonomous Driving: A Survey of Applications and Directions"\*\*, submitted to \*\*IEEE Transactions on Intelligent Transportation Systems\*\*.



We aim to systematically outline the key contributions and latest advancements of 3D Gaussian Splatting (3DGS) in autonomous driving. This project will be continuously updated to track frontier research.



---



\## üìù Abstract



With the rapid development of autonomous driving technology, the understanding and interaction of the driving environment, as a core component, has increasingly higher requirements for real-time performance and accuracy. \*\*3D Gaussian Splatting (3DGS)\*\*, as an efficient 3D scene reconstruction method, features real-time rendering, high-fidelity reconstruction, and flexible editing capabilities. It can significantly enhance the accuracy of perception, planning, and decision-making, and is gradually replacing implicit reconstruction methods represented by Neural Radiance Fields (NeRF).



This paper categorizes and discusses four major application areas of 3DGS in autonomous driving: \*\*Scene Reconstruction, Scene Editing, Simultaneous Localization and Mapping (SLAM), and Autonomous Driving Simulation\*\*. Finally, we analyze the challenges faced by 3DGS in autonomous driving applications and explore future research directions.



\## üóÇÔ∏è Taxonomy \& Paper List



Based on our survey, we categorize 3DGS applications in autonomous driving into the following structure. We will update the paper list under these categories.



\### 1. Scene Reconstruction (Âú∫ÊôØÈáçÂª∫)

\* \*\*Static Scene Reconstruction\*\*: High-fidelity environmental models for HD maps.

\* \*\*Dynamic Scene Reconstruction\*\*: Modeling moving objects (vehicles, pedestrians).

\* \*\*Large-Scale Urban Scene Reconstruction\*\*: City-level 3D maps with memory-efficient strategies.



\### 2. Scene Editing (Âú∫ÊôØÁºñËæë)

\* \*\*Rich and Flexible Editing\*\*: Object removal, replacement, insertion.

\* \*\*Multimodal Fusion\*\*: Joint editing of images and LiDAR point clouds.



\### 3. Simultaneous Localization and Mapping (SLAM)

\* \*\*Dense Reconstruction\*\*: Balancing tracking accuracy and visual fidelity.

\* \*\*LiDAR Integration\*\*: Fusing LiDAR depth for robust initialization and tracking.

\* \*\*Complex Outdoor Scenes\*\*: Handling unbounded environments.



\### 4. Autonomous Driving Simulation (Ëá™Âä®È©æÈ©∂‰ªøÁúü)

\* \*\*3D Asset Generation and Insertion\*\*: Enhancing asset realism via diffusion models.

\* \*\*Physical Simulation\*\*: Integrating kinematic and mechanical properties.

\* \*\*Sensor Simulation Testing\*\*: Adversarial attacks and sensor modeling.

\* \*\*Autonomous Driving Simulator\*\*: Bridging the sim-to-real gap.



---



\## üöÄ Future Research Directions



We also track the latest works related to the future directions proposed in our survey:



\* \*\*Structural Optimization\*\*: Sparse Data Reconstruction, Memory-Efficient 3DGS, Real-Time 3DGS, Photo-realistic 3DGS.

\* \*\*Integration with Foundation Models\*\*: SAM, LLM, Diffusion Models.

\* \*\*Space-Air-Ground Integration\*\*

\* \*\*Vehicle-Road-Cloud Integration\*\*

\* \*\*Quantum Computing\*\*

