**\[4].**

* ğŸ§‘â€ğŸ“ **Author**ï¼š
* ğŸ”— **Link**ï¼š
* ğŸ¤” **Challenge**ï¼š
* ğŸ“– **Introduction**ï¼š



**\[4].**

* ğŸ§‘â€ğŸ“ **Author**ï¼š
* ğŸ”— **Link**ï¼š
* ğŸ¤” **Challenge**ï¼š
* ğŸ“– **Introduction**ï¼š



**\[4]. GS2Mesh: Surface Reconstruction from Gaussian Splatting via Novel Stereo Views**

* ğŸ§‘â€ğŸ“ **Author**ï¼šYaniv Wolf, Amit Bracha, Ron Kimmel
* ğŸ”— **Link**ï¼š\[[arXiv:2404.01810](https://arxiv.org/abs/2404.01810)]
* ğŸ¤” **Challenge**ï¼šDirectly extracting scene geometry from Gaussian properties remains challenging, as these properties are optimized based on photometric loss. While some concurrent models attempt to incorporate geometric constraints during Gaussian optimization, they still produce noisy, unrealistic surfaces.
* ğŸ“– **Introduction**ï¼šThis paper proposes GS2Mesh, bridging the gap between noisy 3D GS representations and smooth 3D mesh representations by infusing real-world knowledge into the deep extraction process.



**\[3]. Gaussian Grouping: Segment and Edit Anything in 3D Scenes**

* ğŸ§‘â€ğŸ“ **Author**ï¼šMingqiao Ye, Martin Danelljan, Fisher Yu, Lei Ke
* ğŸ”— **Link**ï¼š\[[arXiv:2312.00732](https://arxiv.org/abs/2312.00732)]
* ğŸ¤” **Challenge**ï¼šPrevious works focused solely on appearance and geometric modeling, lacking fine-grained object-level scene understanding.
* ğŸ“– **Introduction**ï¼šThis paper proposes Gaussian Grouping, which employs compact identity encoding to enhance each Gaussian. By leveraging the 2D mask predictions from the Segment Anything Model (SAM) and introducing 3D spatial consistency regularization to supervise identity encoding during differentiable rendering, it enables grouping Gaussians based on their object instance or membership within objects in a 3D scene.



**\[2]. GaussianPro: 3D Gaussian Splatting with Progressive Propagation**

* ğŸ§‘â€ğŸ“ **Author**ï¼šKai Cheng, Xiaoxiao Long, Kaizhi Yang, Yao Yao, Wei Yin, Yuexin Ma, Wenping Wang, Xuejin Chen
* ğŸ”— **Link**ï¼š\[[arXiv:2402.14650](https://arxiv.org/abs/2402.14650)]
* ğŸ¤” **Challenge**ï¼šWhen processing large-scale scenes that inevitably include untracked surfaces, SfM technology consistently fails to generate sufficient points on these surfaces and cannot provide a good initialization for 3DGS.
* ğŸ“– **Introduction**ï¼šInspired by the classic Multi-View Stereo (MVS) technique, we propose GaussianPro, a novel approach that employs a progressive propagation strategy to guide 3D Gaussian densification. Unlike the simple splitting and cloning strategies used in 3DGS, our method leverages prior knowledge of existing reconstructed geometry in the scene and patch matching techniques to generate new Gaussian units.



**\[1]. â­3D Gaussian Splatting for Real-Time Radiance Field Rendering**

* ğŸ§‘â€ğŸ“ **Author**ï¼šBernhard Kerbl, Georgios Kopanas, Thomas LeimkÃ¼hler, George Drettakis
* ğŸ”— **Link**ï¼š\[[arXiv:2308.04079](https://arxiv.org/abs/2308.04079)]
* ğŸ¤” **Challenge**ï¼šFor boundless and complete scenes (rather than isolated objects) and high-resolution rendering, there is currently no method capable of achieving real-time display rates.
* ğŸ“– **Introduction**ï¼š3DGS begins with sparse points generated during camera calibration, representing the scene using 3D Gaussians. These Gaussians preserve the ideal properties of continuous volumetric radiation fields for scene optimization while avoiding unnecessary computations in empty space. Subsequently, the 3D Gaussians undergo interleaved optimization/density control, specifically optimizing anisotropic covariance to achieve accurate scene representation. Finally, a fast visible-light-perception rendering algorithm supporting anisotropic scattering accelerates training while enabling real-time rendering.
